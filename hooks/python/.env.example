# Example environment configuration for Claude Code hooks
# Copy this to .env and set your actual values

# Meta-cognitive guard configuration
META_COGNITIVE_ANALYSIS_ENABLED=true
META_COGNITIVE_LLM_PROVIDER=google
META_COGNITIVE_LLM_VERSION=2.0-flash-exp

# Conversation log analysis configuration
CONVERSATION_LOG_ANALYSIS_ENABLED=true
CONVERSATION_LOG_MAX_ENTRIES=5
CONVERSATION_LOG_HOURS_BACK=24
CONVERSATION_LOG_LLM_PROVIDER=google
CONVERSATION_LOG_LLM_VERSION=1.5-flash

# API Keys (required for LLM providers)
GOOGLE_API_KEY=your_google_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
OPENAI_API_KEY=your_openai_api_key_here

# Local LLM configuration (for Ollama)
OLLAMA_API_URL=http://localhost:11434

# Available LLM provider options:
# - google: 1.5-flash, 1.5-flash-8b, 2.0-flash-exp, 1.5-flash-002, 1.5-pro
# - anthropic: haiku, sonnet, opus
# - openai: 4o-mini, 4o, 3.5-turbo
# - local: llama-3.1-8b, llama-3.1-70b, codellama
